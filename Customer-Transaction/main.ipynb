{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30797edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re  \n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16,8]\n",
    "plt.rcParams['font.size'] =14\n",
    "plt.rcParams['font.weight']= 'bold'\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e99b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b8c5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#import torchtext\n",
    "#from textblob import TextBlob\n",
    "#from torchtext.data import Field , TabularDataset , BucketIterator ,LabelField\n",
    "#nlp = spacy.load(r'.\\en_core_web_lg\\en_core_web_lg-3.4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd109eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note : I Checked The Data and Nulls Before Doing all these stuff \n",
    "%run dataset.ipynb import *\n",
    "\n",
    "train , val , test , ids = getData()\n",
    "train_loader = DataLoader(train , batch_size=512 , shuffle = True)\n",
    "val_loader = DataLoader(val , batch_size=512 , shuffle = True)\n",
    "test_loader = DataLoader(test , batch_size=512 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234afa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.ipynb import *\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "basic_model = basic_NN(200 , 64).to(device)\n",
    "optimizer = optim.SGD(basic_model.parameters() , lr = 1e-2 , weight_decay=3e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d08471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss=0.4886074960231781 | valLoss=0.3691258728504181 | Roc = 0.7422528927733493\n",
      "trainLoss=0.2806459069252014 | valLoss=0.2707180082798004 | Roc = 0.8150543337406683\n",
      "trainLoss=0.25643599033355713 | valLoss=0.25440382957458496 | Roc = 0.8296747634459852\n",
      "trainLoss=0.24929551780223846 | valLoss=0.24821774661540985 | Roc = 0.8354622522226196\n",
      "trainLoss=0.24620074033737183 | valLoss=0.24437430500984192 | Roc = 0.8392039530865025\n",
      "trainLoss=0.2443537563085556 | valLoss=0.24442021548748016 | Roc = 0.8415760648435293\n",
      "trainLoss=0.24304607510566711 | valLoss=0.2449781447649002 | Roc = 0.8434042305848596\n",
      "trainLoss=0.24166497588157654 | valLoss=0.2517189681529999 | Roc = 0.8453562516796583\n",
      "trainLoss=0.2407589852809906 | valLoss=0.24336807429790497 | Roc = 0.847329539898424\n",
      "trainLoss=0.23972511291503906 | valLoss=0.24492786824703217 | Roc = 0.8467364948634084\n",
      "trainLoss=0.23866231739521027 | valLoss=0.24906282126903534 | Roc = 0.8492264169135866\n",
      "trainLoss=0.2380996197462082 | valLoss=0.24361924827098846 | Roc = 0.8489039635491069\n",
      "trainLoss=0.23744843900203705 | valLoss=0.24156104028224945 | Roc = 0.8486124876996015\n",
      "trainLoss=0.23646125197410583 | valLoss=0.24221043288707733 | Roc = 0.8505946110065231\n",
      "trainLoss=0.23561584949493408 | valLoss=0.23869192600250244 | Roc = 0.8512696336242119\n",
      "trainLoss=0.23456433415412903 | valLoss=0.2363603413105011 | Roc = 0.8518351339726234\n",
      "trainLoss=0.23413756489753723 | valLoss=0.24040499329566956 | Roc = 0.8527504272230128\n"
     ]
    }
   ],
   "source": [
    "%run Training-Testing.ipynb import *\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(33):\n",
    "    tr_loss = training(basic_model , train_loader , criterion , optimizer , device)\n",
    "    val_loss , true , preds = testing(basic_model , val_loader , criterion , device)\n",
    "    train_loss_list.append(tr_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    \n",
    "    if(epoch % 2 ==0 ):\n",
    "        print(f'trainLoss={tr_loss} | valLoss={val_loss} | Roc = {roc_auc_score(true, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ce060",
   "metadata": {},
   "source": [
    "### Not bad as a vanilla model , But Fortunately we can do better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982fff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try To understand more about data \n",
    "df = pd.read_csv(r\"C:\\Users\\besho\\Downloads\\Standard-Transaction\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702f2bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
       "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
       "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
       "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
       "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
       "\n",
       "    var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0 -4.9200  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  3.1468  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2 -4.9193  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3 -5.8609  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  6.2654  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['ID_code'] , axis = 1 ,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0befb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "choices = random.choices(df.columns[1:] , k = 20)\n",
    "ind = 0\n",
    "\n",
    "fig , ax = plt.subplots(nrows = 4 , ncols = 5)\n",
    "for i in range(4):\n",
    "    for j in range(5):     \n",
    "        ax[i,j].hist(df[choices[ind]])\n",
    "        ax[i,j].set_title(f\"{choices[ind]}\")\n",
    "        ax[i,j].axis(False)\n",
    "        ind +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f128213a",
   "metadata": {},
   "source": [
    "is it make sense the whole features follows Normal Distribution ? Actually No <br>\n",
    "I think the data are result of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf108a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var_0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-0.005373</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.005776</td>\n",
       "      <td>0.003850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1</th>\n",
       "      <td>-0.000544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>-0.000902</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>-0.000832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>-0.004157</td>\n",
       "      <td>-0.004861</td>\n",
       "      <td>0.002287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_2</th>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>-0.000991</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>-0.001932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.003400</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>0.003855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_3</th>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>-0.001699</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.001651</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_4</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>-0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_195</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>-0.000868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>-0.004745</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>-0.004170</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>0.002042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_196</th>\n",
       "      <td>0.004386</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>-0.003242</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>-0.001386</td>\n",
       "      <td>-0.005308</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_197</th>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.004157</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>-0.004583</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004974</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>-0.004170</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.004991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_198</th>\n",
       "      <td>-0.005776</td>\n",
       "      <td>-0.004861</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>-0.001651</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.003025</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_199</th>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.000552</td>\n",
       "      <td>-0.005615</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>-0.004731</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "var_0    1.000000 -0.000544  0.006573  0.003801  0.001326  0.003046  0.006983   \n",
       "var_1   -0.000544  1.000000  0.003980  0.000010  0.000303 -0.000902  0.003258   \n",
       "var_2    0.006573  0.003980  1.000000  0.001001  0.000723  0.001569  0.000883   \n",
       "var_3    0.003801  0.000010  0.001001  1.000000 -0.000322  0.003253 -0.000774   \n",
       "var_4    0.001326  0.000303  0.000723 -0.000322  1.000000 -0.001368  0.000049   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "var_195  0.002073 -0.000785 -0.001070  0.001206  0.003706 -0.001274  0.001244   \n",
       "var_196  0.004386 -0.000377  0.003952 -0.002800  0.000513  0.002880  0.005378   \n",
       "var_197 -0.000753 -0.004157  0.001078  0.001164 -0.000046 -0.000535 -0.003565   \n",
       "var_198 -0.005776 -0.004861 -0.000877 -0.001651 -0.001821 -0.000953 -0.003025   \n",
       "var_199  0.003850  0.002287  0.003855  0.000506 -0.000786  0.002767  0.006096   \n",
       "\n",
       "            var_7     var_8     var_9  ...   var_190   var_191   var_192  \\\n",
       "var_0    0.002429  0.004962 -0.002613  ...  0.002752  0.000206 -0.005373   \n",
       "var_1    0.001511  0.004098 -0.000832  ...  0.006627  0.003621 -0.002604   \n",
       "var_2   -0.000991  0.002648 -0.001932  ...  0.000197  0.001285 -0.003400   \n",
       "var_3    0.002500  0.003553 -0.000826  ...  0.000151  0.002445 -0.001530   \n",
       "var_4    0.004549  0.001194 -0.000918  ...  0.001514  0.004357  0.003347   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "var_195  0.001854  0.001396 -0.000868  ...  0.004571  0.000870 -0.004745   \n",
       "var_196  0.001045 -0.003242  0.000052  ... -0.000847  0.002466 -0.001386   \n",
       "var_197  0.003466 -0.004583  0.003701  ... -0.004974  0.000906 -0.000527   \n",
       "var_198  0.000650  0.002950  0.002343  ... -0.000153 -0.000067  0.003451   \n",
       "var_199 -0.001457  0.000854  0.001070  ... -0.000404  0.003595 -0.001239   \n",
       "\n",
       "          var_193   var_194   var_195   var_196   var_197   var_198   var_199  \n",
       "var_0    0.001616 -0.001514  0.002073  0.004386 -0.000753 -0.005776  0.003850  \n",
       "var_1    0.001153 -0.002557 -0.000785 -0.000377 -0.004157 -0.004861  0.002287  \n",
       "var_2    0.000549  0.002104 -0.001070  0.003952  0.001078 -0.000877  0.003855  \n",
       "var_3   -0.001699 -0.001054  0.001206 -0.002800  0.001164 -0.001651  0.000506  \n",
       "var_4    0.000813 -0.000068  0.003706  0.000513 -0.000046 -0.001821 -0.000786  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "var_195 -0.003143 -0.001201  1.000000  0.002517 -0.004170 -0.000536  0.002042  \n",
       "var_196 -0.005308 -0.005040  0.002517  1.000000 -0.000454  0.000253  0.000607  \n",
       "var_197  0.005068  0.000884 -0.004170 -0.000454  1.000000  0.001183  0.004991  \n",
       "var_198  0.001646  0.003194 -0.000536  0.000253  0.001183  1.000000 -0.004731  \n",
       "var_199 -0.000552 -0.005615  0.002042  0.000607  0.004991 -0.004731  1.000000  \n",
       "\n",
       "[200 rows x 200 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['target'] , axis = 1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe33e2a",
   "metadata": {},
   "source": [
    "Ummm...more weird Results :) <br>\n",
    "But Actually not weird at all , do u know why ? <br>\n",
    "because our hypothesis that the data comes from PCA , and we know that PCA remove correlation . <br>\n",
    "that makes our assumption strong enough to handle this now ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95830816",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.ipynb import *\n",
    "improved_model = improved_NN(200 , 4,8,16).to(device)\n",
    "optimizer = optim.Adam(improved_model.parameters() , lr = 5e-5 , weight_decay=1e-2)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c8f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss=0.5702835321426392 | valLoss=0.3925226628780365 | Roc = 0.8790288514864079\n",
      "trainLoss=0.2588375210762024 | valLoss=0.2207866758108139 | Roc = 0.8936409384614226\n",
      "trainLoss=0.23134732246398926 | valLoss=0.21310845017433167 | Roc = 0.8956606177313108\n",
      "trainLoss=0.2255914956331253 | valLoss=0.21351014077663422 | Roc = 0.8970679405970248\n",
      "trainLoss=0.22225114703178406 | valLoss=0.2094157189130783 | Roc = 0.8978371129776641\n",
      "trainLoss=0.2196778655052185 | valLoss=0.2074815332889557 | Roc = 0.8984890494826482\n",
      "trainLoss=0.21817557513713837 | valLoss=0.21098554134368896 | Roc = 0.8989570903292027\n",
      "trainLoss=0.2165822982788086 | valLoss=0.2050485461950302 | Roc = 0.8987381688801115\n",
      "trainLoss=0.2147856503725052 | valLoss=0.206368550658226 | Roc = 0.899009157172252\n",
      "trainLoss=0.21532559394836426 | valLoss=0.20673060417175293 | Roc = 0.8993428253545147\n",
      "trainLoss=0.21482938528060913 | valLoss=0.20548179745674133 | Roc = 0.8993143643352383\n",
      "trainLoss=0.214742973446846 | valLoss=0.2080259770154953 | Roc = 0.8991885942567824\n",
      "trainLoss=0.2142629474401474 | valLoss=0.20721998810768127 | Roc = 0.8992211445815677\n",
      "trainLoss=0.21367791295051575 | valLoss=0.20476816594600677 | Roc = 0.8993583893333404\n",
      "trainLoss=0.2132750302553177 | valLoss=0.2095947563648224 | Roc = 0.899347283928414\n",
      "trainLoss=0.21341507136821747 | valLoss=0.2083502858877182 | Roc = 0.8993380658952604\n",
      "trainLoss=0.2135886400938034 | valLoss=0.20598196983337402 | Roc = 0.8991201291618771\n"
     ]
    }
   ],
   "source": [
    "%run Training-Testing.ipynb import *\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(33):\n",
    "    tr_loss = training(improved_model , train_loader , criterion , optimizer , device)\n",
    "    val_loss , true , preds = testing(improved_model , val_loader , criterion , device)\n",
    "    train_loss_list.append(tr_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    \n",
    "    if(epoch % 2 ==0 ):\n",
    "        print(f'trainLoss={tr_loss} | valLoss={val_loss} | Roc = {roc_auc_score(true, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12291179",
   "metadata": {},
   "source": [
    "### Nice Improvement , but i think i can do better than this "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953dd00",
   "metadata": {},
   "source": [
    "##### Assumption 1: what if there is some features are \" Discreate \" before doing PCA ? \n",
    "##### we can check the count of each feature and doing something similar to one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f23dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in df.columns[1:]:\n",
    "    dic[i] = {}\n",
    "\n",
    "for i in df.columns[1:]:\n",
    "    for j in df[i]:\n",
    "        if(j in dic[i].keys()):\n",
    "            dic[i][j] +=1\n",
    "        else:\n",
    "            dic[i][j] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db12ce1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.6829    11\n",
       "8.6649     11\n",
       "13.0656    11\n",
       "9.8379     10\n",
       "8.7260     10\n",
       "Name: var_0, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if it correct\n",
    "first_five = df['var_0'].value_counts().index[:5] \n",
    "df['var_0'].value_counts().iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa06bafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in first_five:\n",
    "    print(dic['var_0'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_unique(feature , x):\n",
    "    if(x in dic[feature].keys()):\n",
    "        return dic[feature][x]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test = pd.read_csv(r\"C:\\Users\\besho\\Downloads\\Standard-Transaction\\test.csv\")\n",
    "submit_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f94bbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns[1:]:\n",
    "    df[f'{i}_count'] = df[i].apply(lambda x : n_unique(i , x) )\n",
    "\n",
    "for i in submit_test.columns[1:]:\n",
    "    submit_test[f'{i}_count'] = submit_test[i].apply(lambda x : n_unique(i , x) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b622ca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_count</th>\n",
       "      <th>var_191_count</th>\n",
       "      <th>var_192_count</th>\n",
       "      <th>var_193_count</th>\n",
       "      <th>var_194_count</th>\n",
       "      <th>var_195_count</th>\n",
       "      <th>var_196_count</th>\n",
       "      <th>var_197_count</th>\n",
       "      <th>var_198_count</th>\n",
       "      <th>var_199_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
       "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
       "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
       "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
       "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
       "\n",
       "    var_8  ...  var_190_count  var_191_count  var_192_count  var_193_count  \\\n",
       "0 -4.9200  ...              3              6              7              3   \n",
       "1  3.1468  ...              5              4              6              1   \n",
       "2 -4.9193  ...              3              4              3              1   \n",
       "3 -5.8609  ...              1              2              4              4   \n",
       "4  6.2654  ...              3              4              1              1   \n",
       "\n",
       "   var_194_count  var_195_count  var_196_count  var_197_count  var_198_count  \\\n",
       "0              4              4              3             13              5   \n",
       "1              1              2              2             13              2   \n",
       "2              2              2              3              8              2   \n",
       "3              3              7              4              4              2   \n",
       "4              1              5              3              6              2   \n",
       "\n",
       "   var_199_count  \n",
       "0              2  \n",
       "1              1  \n",
       "2              2  \n",
       "3              2  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ffb4a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# check the result \n",
    "for i in range(5):\n",
    "    print(df['var_190'].value_counts()[df['var_190'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3613d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_dataset.csv\" , index = False)\n",
    "submit_test.to_csv(\"final_test_dataset.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ae9c457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_count</th>\n",
       "      <th>var_191_count</th>\n",
       "      <th>var_192_count</th>\n",
       "      <th>var_193_count</th>\n",
       "      <th>var_194_count</th>\n",
       "      <th>var_195_count</th>\n",
       "      <th>var_196_count</th>\n",
       "      <th>var_197_count</th>\n",
       "      <th>var_198_count</th>\n",
       "      <th>var_199_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266   \n",
       "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338   \n",
       "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155   \n",
       "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250   \n",
       "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514   \n",
       "\n",
       "    var_8  ...  var_190_count  var_191_count  var_192_count  var_193_count  \\\n",
       "0 -4.9200  ...              3              6              7              3   \n",
       "1  3.1468  ...              5              4              6              1   \n",
       "2 -4.9193  ...              3              4              3              1   \n",
       "3 -5.8609  ...              1              2              4              4   \n",
       "4  6.2654  ...              3              4              1              1   \n",
       "\n",
       "   var_194_count  var_195_count  var_196_count  var_197_count  var_198_count  \\\n",
       "0              4              4              3             13              5   \n",
       "1              1              2              2             13              2   \n",
       "2              2              2              3              8              2   \n",
       "3              3              7              4              4              2   \n",
       "4              1              5              3              6              2   \n",
       "\n",
       "   var_199_count  \n",
       "0              2  \n",
       "1              1  \n",
       "2              2  \n",
       "3              2  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('final_dataset.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d983fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataset.ipynb import *\n",
    "train , val , df , test = getAllData()\n",
    "df_loader = DataLoader(df , batch_size=512 , shuffle = True)\n",
    "final_train_loader = DataLoader(train , batch_size=512 , shuffle = True)\n",
    "final_val_loader = DataLoader(val , batch_size=512 , shuffle = True)\n",
    "final_test_loader = DataLoader(test , batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f30f8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.ipynb import *\n",
    "modify_improved_model = modify_Improved_NN(400 , 128,1,1).to(device)\n",
    "optimizer = optim.Adam(modify_improved_model.parameters() , lr = 5e-5 , weight_decay=7e-2)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc9c73d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - trainLoss=0.4564850628376007 | valLoss=0.3013485372066498 | Roc = 0.8939314502981095\n",
      "2 - trainLoss=0.25363826751708984 | valLoss=0.24156080186367035 | Roc = 0.9028449642667218\n",
      "4 - trainLoss=0.24405129253864288 | valLoss=0.23182623088359833 | Roc = 0.9067221899762222\n",
      "6 - trainLoss=0.24123027920722961 | valLoss=0.23335425555706024 | Roc = 0.9088432615913103\n",
      "8 - trainLoss=0.23930887877941132 | valLoss=0.23119454085826874 | Roc = 0.9106068577945189\n",
      "10 - trainLoss=0.23768019676208496 | valLoss=0.22913984954357147 | Roc = 0.9109120266200985\n",
      "12 - trainLoss=0.2364293783903122 | valLoss=0.23026621341705322 | Roc = 0.9118468797553769\n",
      "14 - trainLoss=0.2358826845884323 | valLoss=0.2309526950120926 | Roc = 0.9129605694481354\n",
      "16 - trainLoss=0.2348005473613739 | valLoss=0.23177485167980194 | Roc = 0.9137213167782046\n",
      "18 - trainLoss=0.23422259092330933 | valLoss=0.2332783043384552 | Roc = 0.9137291825364577\n",
      "20 - trainLoss=0.2339877039194107 | valLoss=0.2304922193288803 | Roc = 0.9143965434045391\n",
      "22 - trainLoss=0.2334863543510437 | valLoss=0.22850143909454346 | Roc = 0.9149522161540872\n",
      "24 - trainLoss=0.23279397189617157 | valLoss=0.22673673927783966 | Roc = 0.9146781855636025\n",
      "26 - trainLoss=0.23322422802448273 | valLoss=0.22499702870845795 | Roc = 0.9157194735641467\n",
      "28 - trainLoss=0.2330133616924286 | valLoss=0.225465327501297 | Roc = 0.9152936211298951\n",
      "30 - trainLoss=0.23281048238277435 | valLoss=0.22699721157550812 | Roc = 0.915596714073135\n",
      "32 - trainLoss=0.23293550312519073 | valLoss=0.2345234900712967 | Roc = 0.9152973068801717\n",
      "34 - trainLoss=0.23285412788391113 | valLoss=0.23226891458034515 | Roc = 0.915514907362974\n"
     ]
    }
   ],
   "source": [
    "%run Training-Testing.ipynb import *\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(35):\n",
    "    tr_loss = training(modify_improved_model , final_train_loader , criterion , optimizer , device)\n",
    "    val_loss , true , preds = testing(modify_improved_model , final_val_loader , criterion , device)\n",
    "    train_loss_list.append(tr_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    \n",
    "    if(epoch % 2 ==0 ):\n",
    "        print(f'{epoch} - trainLoss={tr_loss} | valLoss={val_loss} | Roc = {roc_auc_score(true, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f1260",
   "metadata": {},
   "source": [
    "### Time to train on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "73dcd17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run models.ipynb import *\n",
    "\n",
    "final_model = modify_Improved_NN(400 , 128,1,1).to(device)\n",
    "optimizer = optim.Adam(final_model.parameters() , lr = 5e-5 , weight_decay=5e-2)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48acde94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Train Loss = 0.43681636452674866 \n",
      "2 - Train Loss = 0.2396065592765808 \n",
      "4 - Train Loss = 0.22923019528388977 \n",
      "6 - Train Loss = 0.2259143739938736 \n",
      "8 - Train Loss = 0.22433750331401825 \n",
      "10 - Train Loss = 0.22271564602851868 \n",
      "12 - Train Loss = 0.2221594750881195 \n",
      "14 - Train Loss = 0.22125589847564697 \n",
      "16 - Train Loss = 0.22046087682247162 \n",
      "18 - Train Loss = 0.22027331590652466 \n",
      "20 - Train Loss = 0.21921519935131073 \n",
      "22 - Train Loss = 0.21888846158981323 \n",
      "24 - Train Loss = 0.21832618117332458 \n",
      "26 - Train Loss = 0.21820899844169617 \n",
      "28 - Train Loss = 0.21739882230758667 \n",
      "30 - Train Loss = 0.21748793125152588 \n",
      "32 - Train Loss = 0.217863529920578 \n",
      "34 - Train Loss = 0.21793784201145172 \n"
     ]
    }
   ],
   "source": [
    "%run Training-Testing.ipynb import *\n",
    "\n",
    "for epoch in range(35):\n",
    "    tr_loss = training(final_model , df_loader , criterion , optimizer , device)    \n",
    "    if(epoch % 2 ==0 ):\n",
    "        print(f'{epoch} - Train Loss = {tr_loss} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3add634",
   "metadata": {},
   "source": [
    "### I know that i repeat my self alot , like evey time i call function from any file i import the whole file agian\n",
    "### but i did that to clarify to u from any notebook i'm calling this function .\n",
    "### also i did that too in NN Archeticture , and i leave some printing and notes to clarify to you the complected things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc9b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
